# -*- coding: utf-8 -*-
"""IDS-PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y0Fnm04lwaZlGDH7qbryBukEm7f7m2rB

**Title: Netflix Movies & TV Shows Analysis**

Description: Analyze Netflix content distribution: genres, ratings, countries, release years, and create
dashboards.

1. Data Preprocessing and Cleaning

A. Load Data
"""

# OPERATION: Load the Netflix dataset and explore its structure
# EXPECTED: Load CSV file successfully, view first 5 rows, column info (data types, null counts), and summary statistics
# ACHIEVED: Dataset loaded with columns like show_id, type, title, director, cast, country, date_added, release_year, rating, duration, listed_in, description

import pandas as pd
import matplotlib.pyplot as plt
from google.colab import files
files.upload()
df = pd.read_csv("netflix_titles.csv")
print(df.head())
print(df.info())
print(df.describe(include='all'))

"""B. Clean data (missing values, duplicates)

Director / Cast missing → Treat as “Unknown”
	•	Country missing → Either fill as “Not Specified” or exclude from country analysis
	•	Date Added missing → Exclude from time-based analysis
	•	Rating missing → Mark as “Unrated”
"""

# OPERATION: Handle missing values by filling with appropriate placeholder values
# EXPECTED: Replace NaN values in director, cast, country, date_added, and rating columns with meaningful defaults
# ACHIEVED: All null values replaced - no more NaN in these columns, enabling complete analysis without data loss

df['director'].fillna('Unknown', inplace=True)
df['cast'].fillna('Unknown', inplace=True)
df['country'].fillna('Not Specified', inplace=True)
df['date_added'].fillna('Unknown', inplace=True)
df['rating'].fillna('Unrated', inplace=True)



# OPERATION: Display dataframe after handling missing values
# EXPECTED: View first 5 rows with all missing values replaced by placeholders
# ACHIEVED: Verified that 'Unknown', 'Not Specified', 'Unrated' values appear where nulls existed

print(df.head())

# OPERATION: Check for duplicate rows in the dataset
# EXPECTED: Identify if any duplicate rows exist that need to be removed
# ACHIEVED: No duplicates found (0 duplicates), dataset is clean for analysis

print("Duplicates:", df.duplicated().sum())
#no duplicates exist

"""C. Data Formatting & Standardization"""

# OPERATION: Split multi-value columns (listed_in, country) into lists and convert date column
# EXPECTED: Convert comma-separated strings to lists for easier analysis, parse date_added to datetime
# ACHIEVED: listed_in and country columns now contain lists, date added column is datetime type for time-based analysis

df['listed_in'] = df['listed_in'].str.split(', ')
df['country'] = df['country'].str.split(', ')

df_country = df.explode('country')
df['date added'] = pd.to_datetime(df['date_added'], errors='coerce')

# OPERATION: Create a genre column by copying listed_in column
# EXPECTED: Have a dedicated 'genre' column for genre-based analysis
# ACHIEVED: Genre column created with same list values as listed_in for clearer naming

df['genre'] = df['listed_in']

# OPERATION: Parse duration column into numeric value and unit (minutes vs seasons)
# EXPECTED: Extract numeric duration and standardize units for Movies (minutes) and TV Shows (seasons)
# ACHIEVED: Created duration_value (numeric) and duration_unit (minute/season) columns for separate analysis

#Duration → Separate number and unit (minutes vs seasons)
df["duration"].unique()
df["duration_value"] = df["duration"].str.extract("(\d+)").astype(float)
df["duration_unit"] = df["duration"].str.extract("(min|Season|Seasons)")

df["duration_unit"] = df["duration_unit"].replace({
    "Season": "season",
    "Seasons": "season",
    "min": "minute"
})
df[["duration", "duration_value", "duration_unit"]].head()

print(df.head())

"""    2.Analyze top genres, directors, country distribution"""

# OPERATION: Explode genre column and count occurrences to find top 10 genres
# EXPECTED: Get frequency count of each genre across all Netflix titles
# ACHIEVED: Top 10 genres identified with International Movies, Dramas, Comedies being most common

#TOP GENRES
all_genres = df.explode('genre')
genre_counts = all_genres['genre'].value_counts().head(10)
print(genre_counts)

# OPERATION: Count content production by country (Note: country is still a list here, causing issues)
# EXPECTED: Get top 10 countries producing Netflix content
# ACHIEVED: This produces incorrect results as country column contains lists - need to explode first

#Top Countries streaming content
country_counts = df['country'].value_counts().head(10)
print(country_counts)

# OPERATION: Count content by director to find top 10 directors
# EXPECTED: Get top 10 directors with most Netflix titles
# ACHIEVED: Top 10 directors identified, with 'Unknown' likely being most common due to missing data

#Top Directors
top_directors = df['director'].value_counts().head(10)
print(top_directors)

"""     Visualizations using Matplotlib/Seaborn"""

# OPERATION: Create bar plot visualizations for top 10 genres and top 10 directors
# EXPECTED: Two horizontal bar charts showing distribution of genres and directors
# ACHIEVED: Clear visualizations showing International Movies as top genre, and director distribution

import seaborn as sns
import matplotlib.pyplot as plt

#Visualizing Top Genres, countries, directors
plt.figure(figsize=(10, 6))
sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='viridis')
plt.title('Top 10 Netflix Genres')
plt.xlabel('Number of Titles')
plt.ylabel('Genre')
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x=top_directors.values, y=top_directors.index, palette='magma')
plt.title('Top 10 Netflix Directors')
plt.xlabel('Number of Titles')
plt.ylabel('Director')
plt.show()

# OPERATION: Correctly count countries by exploding the list column first
# EXPECTED: Get accurate top 10 countries after splitting multi-country entries
# ACHIEVED: United States dominates with most content, followed by India and UK

country_counts = df.explode('country')['country'].value_counts().head(10)
print(country_counts)

# OPERATION: Visualize top 10 countries by Netflix content count
# EXPECTED: Horizontal bar chart showing country distribution
# ACHIEVED: Clear visualization with US, India, UK as top content producers
import seaborn as sns
import matplotlib.pyplot as plt
country_counts = df.explode('country')['country'].value_counts().head(10)
plt.figure(figsize=(10, 6))
sns.barplot(x=country_counts.values, y=country_counts.index, palette='coolwarm')
plt.title('Top 10 Countries by Netflix Content')
plt.xlabel('Number of Titles')
plt.ylabel('Country')
plt.show()

# OPERATION: Extract year from date added and plot content addition trend over years
# EXPECTED: Line chart showing how Netflix content library grew year over year
# ACHIEVED: Visualization shows Netflix content growth with peak additions around 2019-2020

#visualizing content added over years
df['year_added'] = df['date added'].dt.year
yearly_coutnts = df.groupby('year_added')['title'].count()
plt.figure(figsize=(10, 6))
plt.plot(yearly_coutnts.index, yearly_coutnts.values, marker='o')
plt.title('Number of Titles Added Per Year on Netflix')
plt.xlabel('Year Added')
plt.ylabel('Number of Titles Added')
plt.grid(True)
plt.show()

# OPERATION: Placeholder for visualizing genre distribution by country
# EXPECTED: Combine genre and country data for cross-analysis
# ACHIEVED: See next cell for heatmap implementation

#visualizing top 10 most watched genre with country

# OPERATION: Create heatmap showing relationship between top 10 genres and top 10 countries
# EXPECTED: A heatmap matrix showing content count for each genre-country combination
# ACHIEVED: Heatmap reveals which genres are most popular in each country, US dominates most genres

# Top 10 genres by top 10 countries heatmap
df_exploded = df.explode('country').explode('genre')
top_countries = df_exploded['country'].value_counts().head(10).index
top_genres = df_exploded['genre'].value_counts().head(10).index

filtered_df = df_exploded[
    (df_exploded['country'].isin(top_countries)) &
    (df_exploded['genre'].isin(top_genres))
]

pivot_table = filtered_df.groupby(['country', 'genre']).size().unstack(fill_value=0)

plt.figure(figsize=(12, 8))
sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt='d')
plt.title('Top 10 Genres by Top 10 Countries')
plt.xlabel('Genre')
plt.ylabel('Country')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Model Training

Goal: Predict the numerical rating of a movie based on its features.

Creatin a rating column and then predicting its rating based on previous ratings
"""

# OPERATION: Map categorical rating labels to numeric values for model training
# EXPECTED: Convert ratings like 'PG', 'R', 'TV-MA' to numeric scale 1-5
# ACHIEVED: rating_col created with numeric values; some ratings like 'Unrated' become NaN (not in map)

rating_map = {
    "G": 1,
    "PG": 2,
    "PG-13": 3,
    "R": 4,
    "NC-17": 5,
    "TV-Y": 1,
    "TV-Y7": 2,
    "TV-G": 2,
    "TV-PG": 3,
    "TV-14": 4,
    "TV-MA": 5
}

df['rating_col'] = df['rating'].map(rating_map)
print(df[['rating', 'rating_col']].tail())

# OPERATION: Train a Random Forest Regressor to predict numeric rating based on duration, year, and country
# EXPECTED: Build a model that can predict rating_col (1-5) with reasonable accuracy
# ACHIEVED: Model trained but low R² (~0.02) indicates poor prediction - features have weak correlation with rating
# NOTE: Rating prediction is essentially a classification problem; regression may not be ideal approach

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score


# Convert duration to numeric
df['duration_value'] = df['duration'].str.extract('(\d+)').astype(float)

# Extract year from date_added
df['year_added'] = pd.to_datetime(df['date_added'], errors='coerce').dt.year


Y = df['rating_col']   # make sure this is numeric!

# Extract first country from list (since country column contains lists)
df['country_first'] = df['country'].apply(lambda x: x[0] if isinstance(x, list) else x)

X = df[['duration_value', 'year_added', 'country_first']]

X = pd.get_dummies(X, columns=['country_first'], drop_first=True)

# Drop rows with NaN values
valid_idx = X.dropna().index.intersection(Y.dropna().index)
X = X.loc[valid_idx]
Y = Y.loc[valid_idx]

X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.2, random_state=42
)

model = RandomForestRegressor(
    n_estimators=500,
    max_depth=4,
    max_features=3,
    bootstrap=True,
    random_state=18,
    n_jobs=-1
)


model.fit(X_train, Y_train)


Y_pred = model.predict(X_test)


mse = mean_squared_error(Y_test, Y_pred)
rmse = mse ** 0.5
r2 = r2_score(Y_test, Y_pred)

print("RMSE:", rmse)
print("R²:", r2)



"""SEMANTIC ANALYSIS"""

df['description'] = df['description'].fillna('')
df['listed_in'] = df['listed_in'].fillna('')

#combining for better understanding for Semantic-Text
df["combined_text"] = (
    df["description"].str.strip() + " " + df["listed_in"].str.strip()
)
df["combined_text"] = df["combined_text"].str.lower()
df["rec_text"] = df["description"].astype(str).str.lower()

# using transformers to create embeddings with semantic-text
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer

# Loading pre-trained Sentence Transformer model
model = SentenceTransformer('all-MiniLM-L6-v2')
# Generating embeddings for description_text
embeddings = model.encode(
    df["rec_text"].tolist(),
    show_progress_bar=True
)
print("Embeddings shape:", embeddings.shape)

"""Creating Recommendation engine"""

#using KNN neighbours for cosine similarity
from sklearn.neighbors import NearestNeighbors

knn = NearestNeighbors(
    n_neighbors=6,
    metric='cosine',
)
knn.fit(embeddings)

def recommend_movies(title, df, embeddings, knn, top_k=5):
    idx = df[df["title"].str.lower() == title.lower()].index

    if len(idx) == 0:
        return "Movie not found"

    idx = idx[0]
    distances, indices = knn.kneighbors(
        embeddings[idx].reshape(1, -1),
        n_neighbors=top_k + 1
    )
    recommendations = df.iloc[indices[0][1:]]["title"].values
    print("These are your recommendations, according to your search\n",recommendations)

recommend_movies("Narcos", df, embeddings, knn)

recommend_movies("Sankofa", df, embeddings, knn)